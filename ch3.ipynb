{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 我们将介绍神经网络的整个训练过程，包括：定义简单的神经网络架构、数据处理、指定损失函数和如何训练模型\n",
    "### 我们将从经典算法————线性神经网络开始，介绍神经网络的基础知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回归是为单个或多个因变量和自变量之间关系建模的一类方法\n",
    "#### 在一些科学领域，回归经常用来表示输入和输出之间的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在机器学习领域中的大多数任务通常都与预测（prediction）有关\n",
    "#### 但不是所有预测都是回归问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 线性回归的基本元素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线性回归（linear regression）可以追溯到19世纪初，它在回归的各种标准工具中最简单而且最流行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线性回归基于几个基本的假设：\n",
    "#### 1. 首先，假设自变量$\\chi$和因变量$y$的关系是线性的，即$y$可以表示为$\\chi$中元素的加权和\n",
    "#### 2. 这里通常允许包含观测值的一些噪声，其次，我们假设任何噪声都比较正常，如噪声遵循正态分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 为开发一个能预测__的模型，我们需要数据集，在ml中称为训练数据集（training dataset）\n",
    "#### 每行数据称为样本（sample），也可以称为数据点（data point）或数据样本（data instance）\n",
    "#### 预测的目标叫做标签（label）或者目标（target）。\n",
    "#### 预测所依据的自变量叫做特征（feature）或者协变量（covariate）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通常n表示数据集中的样本数。对索引为i的样本其输入表示为$x^{(i)} = [x_1^{(i)}, x_2^{(i)}]^⊤$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 每个解决方案的核心都是一个模型，该模型描述如何将特征转换为目标的估计\n",
    "#### 线性假设是指目标（房屋价格）可以表示为特征（面积和房龄）的加权和"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\textrm{price} = w_{\\textrm{area}} \\cdot \\textrm{area} + w_{\\textrm{age}} \\cdot \\textrm{age} + b.\\textrm{price} = w_{\\textrm{area}} \\cdot \\textrm{area} + w_{\\textrm{age}} \\cdot \\textrm{age} + b. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $w_{area}$ 和 $w_{age}$称为权重（weight），权重决定了每个特征对我们预测值的影响\n",
    "#### $b$称为偏置（bias）、偏移量（offset）或截距（intercept）\n",
    "#### 偏置是指当所有特征都取值为0时，预测值应该为多少\n",
    "#### 如果没有偏置项，我们模型的表达能力会出问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 严格来说，这个公式是输入特征的一个仿射变换（affine transformation）\n",
    "#### 仿射变换的特点是通过加权和对特征进行线性变换（linear transformation），并通过偏置项进行平移（translation）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 我们的目标是找到权重$w$和偏置$b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在机器学习中，我们的数据集通常都是高维的，建模时采用线性代数表示法更方便\n",
    "#### 当我们输入包含$d$个特征时，我们将预测结果$\\hat y$表示为\n",
    "#### $$ \\hat{y} = w_1  x_1 + \\cdots + w_d  x_d + b. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将所有特征收集到$\\chi \\in \\mathbb R^d$中，可以通过点积来表示公式\n",
    "#### $$ \\hat{y} = \\mathbf{w}^\\top \\mathbf{x} + b. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 向量$\\chi$对应于单个数据样本的特征\n",
    "#### 用符号表示的矩阵$X \\in R^{n×d}$ 可以很方便地引用我们整个数据集的n个样本\n",
    "#### 其中，X的每一行是一个样本，每一列是一种特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对于特征集合X，预测值$\\hat y \\in R^n $可以通过矩阵‐向量乘法表示为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ {\\hat{\\mathbf{y}}} = \\mathbf{X} \\mathbf{w} + b, $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 这个过程中的求和将使用广播机制\n",
    "#### 线性回归的目标是找到一组权重向量w和偏置b能够使得新样本预测标签的误差尽可能小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 无论如何，都可能会出现少量的观测误差。因此，即使确信特征与标签的潜在关系是线性的，我们也会加入一个噪声项来考虑观测误差带来的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在开始寻找最好的模型参数（model parameters）w和b之前，我们还需要两个东西：（1）一种模型质量的度量方式；（2）一种能够更新模型以提高模型预测质量的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 损失函数和平方误差\n",
    "在线性回归中，损失函数用于量化模型预测值与实际标签之间的差距。通常选择非负数作为损失，数值越小表示拟合效果越好，完美预测的损失为0。回归问题中常用的损失函数是平方误差函数，定义为：\n",
    "\\[ l^{(i)}(w, b) = \\frac{1}{2} \\left( \\hat{y}^{(i)} - y^{(i)} \\right)^2 \\]\n",
    "\n",
    "#### 平方误差函数的特点\n",
    "平方误差函数中的常数 \\(\\frac{1}{2}\\) 是为了求导时的方便。平方误差函数使得预测值与实际值之间较大的差异导致更大的损失，这有助于模型更好地拟合数据。\n",
    "\n",
    "#### 模型在整个数据集上的质量度量\n",
    "为了度量模型在整个数据集上的质量，计算所有训练样本上的损失均值：\n",
    "\\[ L(w, b) = \\frac{1}{n} \\sum_{i=1}^{n} l^{(i)}(w, b) = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{2} \\left( w^\\top x^{(i)} + b - y^{(i)} \\right)^2 \\]\n",
    "\n",
    "#### 模型训练的目标\n",
    "训练模型的目标是找到一组参数 \\( w^*, b^* \\)，使得它们能最小化所有训练样本上的总损失：\n",
    "\\[ w^*, b^* = \\arg \\min_{w,b} L(w, b) \\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
